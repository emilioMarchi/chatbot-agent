<!DOCTYPE html>
<html lang="es">
<head>
<meta charset="UTF-8">
<title>Asistente de Voz OVNI</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<style>
  body { font-family: sans-serif; display:flex; flex-direction:column; align-items:center; padding:20px; background:#f0f4f8; }
  #chat-container { width:100%; max-width:600px; background:#fff; padding:20px; border-radius:12px; box-shadow:0 5px 20px rgba(0,0,0,0.1); }
  #messages { max-height:60vh; overflow-y:auto; margin-bottom:10px; }
  .message { padding:10px 15px; border-radius:20px; margin:6px 0; max-width:80%; }
  .user { background:#a8e6cf; align-self:flex-end; text-align:right; }
  .bot { background:#ffe0b2; align-self:flex-start; text-align:left; }
  button { padding:12px 20px; border:none; border-radius:25px; cursor:pointer; background:#2196F3; color:white; font-size:16px; }
  .status { font-size:12px; color:#555; margin-bottom:10px; }
</style>
</head>
<body>

<h2>Asistente de Voz OVNI</h2>
<div id="chat-container">
  <div id="messages"></div>
  <div class="status" id="status">Esperando iniciar...</div>
  <button id="start-btn">Iniciar Conversación</button>
</div>

<script>
const messagesContainer = document.getElementById('messages');
const statusEl = document.getElementById('status');
const startBtn = document.getElementById('start-btn');
let userId = sessionStorage.getItem('userId');
if(!userId){ userId = crypto.randomUUID(); sessionStorage.setItem('userId', userId); }

function appendMessage(text, className) {
  const div = document.createElement('div');
  div.className = 'message ' + className;
  div.innerText = text;
  messagesContainer.appendChild(div);
  messagesContainer.scrollTop = messagesContainer.scrollHeight;
}

function setStatus(text) {
  statusEl.innerText = text;
  console.log("[STATUS]", text);
}

function appendAudioMessage(url) {
  const audio = document.createElement('audio');
  audio.src = url;
  audio.autoplay = true;
  messagesContainer.appendChild(audio);
  messagesContainer.scrollTop = messagesContainer.scrollHeight;
  return audio;
}

async function startConversation() {
  startBtn.disabled = true;
  appendMessage("Asistente escuchando...", "bot");
  setStatus("Grabación iniciada");

  let mediaRecorder, audioChunks=[], micStream;
  let recognizing = true;

  async function startListening() {
    try {
      micStream = await navigator.mediaDevices.getUserMedia({ audio:true });
      setStatus("Asistente escuchando...");

      mediaRecorder = new MediaRecorder(micStream);
      audioChunks = [];

      const audioContext = new AudioContext();
      const analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(micStream);
      source.connect(analyser);
      analyser.fftSize = 2048;
      const dataArray = new Uint8Array(analyser.fftSize);

      let silenceStart = null;
      let maxRecordingTime = 10000; // 10s
      let recordingStart = Date.now();

      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
      mediaRecorder.start();

      function checkSilence() {
        analyser.getByteTimeDomainData(dataArray);
        const avg = dataArray.reduce((a,v)=>a+Math.abs(v-128),0)/dataArray.length;
        const now = Date.now();

        if(avg < 5) {
          if(!silenceStart) silenceStart = now;
          if(now - silenceStart > 700 || now - recordingStart > maxRecordingTime) {
            setStatus("Procesando mensaje...");
            stopListening();
            return;
          }
        } else {
          silenceStart = null;
        }

        if(recognizing) requestAnimationFrame(checkSilence);
      }

      checkSilence();

    } catch(err) {
      console.error("Error getUserMedia:", err);
      alert("Error accediendo al micrófono: " + err.message);
      setStatus("Error acceso micrófono ❌");
    }
  }

  async function stopListening() {
    if(!mediaRecorder) return;
    mediaRecorder.stop();
    micStream.getTracks().forEach(t=>t.stop());
    recognizing = false;

    const audioBlob = new Blob(audioChunks,{ type:'audio/webm' });
    audioChunks = [];
    mediaRecorder = null;

    if(audioBlob.size < 100){
      setStatus("Audio muy corto, reiniciando escucha...");
      recognizing = true;
      startListening();
      return;
    }

    appendMessage("Procesando tu mensaje...", "user");
    setStatus("Enviando audio al servidor...");

    const formData = new FormData();
    formData.append("audio", audioBlob, "voz.webm");
    formData.append("userId", userId);

    try {
      const res = await fetch("/voice-session", { method:"POST", body:formData });
      setStatus("Respuesta recibida");
      const data = await res.json();

      if(data.userText) appendMessage(data.userText, "user");

      if(data.audioBase64){
        setStatus("Reproduciendo respuesta del asistente...");
        const botAudioBlob = new Blob([Uint8Array.from(atob(data.audioBase64), c=>c.charCodeAt(0))], {type:'audio/mp3'});
        const audioEl = appendAudioMessage(URL.createObjectURL(botAudioBlob));
        audioEl.onended = () => {
          setStatus("Respuesta terminada, asistente escuchando...");
          recognizing = true;
          startListening();
        };
      } else if(data.reply){
        appendMessage(data.reply, "bot");
        setStatus("Respuesta del bot recibida, reiniciando escucha...");
        recognizing = true;
        startListening();
      }
    } catch(err){
      console.error("Error fetch /voice-session:", err);
      alert("Error procesando audio: " + err.message);
      setStatus("Error procesando audio ❌");
    }
  }

  await startListening();
}

startBtn.onclick = startConversation;
</script>
</body>
</html>
